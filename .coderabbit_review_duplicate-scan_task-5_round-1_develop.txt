Starting CodeRabbit review in plain text mode...

Connecting to review service
Setting up
Analyzing
Reviewing

============================================================================
File: tests/test_detector.py
Line: 44 to 84
Type: potential_issue

Prompt for AI Agent:
In tests/test_detector.py around lines 44 to 84, add two unit tests to cover None hash edge cases: 1) test_find_duplicates_same_size_none_partial_hash — create two FileMeta objects with same size and partial_hash=None (other fields as in existing tests), call detector.find_duplicates and assert it returns an empty list; 2) test_find_duplicates_same_size_and_partial_none_full_hash — create two FileMeta objects with same size and partial_hash="hash1" but full_hash=None, call detector.find_duplicates and assert it returns an empty list; place these tests alongside the existing similar tests to ensure None is handled distinctly from empty string.



============================================================================
File: src/services/detector.py
Line: 52 to 70
Type: potential_issue

Prompt for AI Agent:
In src/services/detector.py around lines 52 to 70, the method _group_by_key must be made generic over the key type because key_func returns int or Optional[str]; define a TypeVar K (bound to Hashable) at module top, import TypeVar and Callable (and Hashable if not present), and change the signature to accept key_func: Callable[[FileMeta], K] and return Dict[K, List[FileMeta]] (or Dict[K, List[FileMeta]] with K bound to Hashable); update imports accordingly so typing is consistent across calls.



============================================================================
File: src/services/detector.py
Line: 42 to 49
Type: potential_issue

Prompt for AI Agent:
In src/services/detector.py around lines 42 to 49, files with None full_hash are being normalized to "" and thus incorrectly grouped as duplicates; instead filter out or skip files that have no full_hash before grouping, and use the actual full_hash as the grouping key (e.g., only pass files where f.full_hash is not None to _group_by_key or filter files_with_same_partial to those with full_hash present) so that files lacking a full hash are not considered equal and are not placed into duplicate groups.



============================================================================
File: src/services/detector.py
Line: 31 to 37
Type: potential_issue

Prompt for AI Agent:
In src/services/detector.py around lines 31 to 37, files with partial_hash==None are being collapsed into the same key by using f.partial_hash or "", producing false duplicate groups; instead filter out files that have no partial_hash before grouping (or change the grouping key function to skip None keys), so only files with a non-None partial_hash are passed into _group_by_key and then extend partial_hash_groups with groups of size >= 2.



Review completed ✔
